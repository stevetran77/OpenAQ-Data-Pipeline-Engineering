D∆∞·ªõi ƒë√¢y l√† `epic.md` m·ªõi, vi·∫øt b√°m s√°t ki·∫øn tr√∫c trong `architecture.md` b·∫°n v·ª´a cung c·∫•p (Airflow ‚Üí Lambda ‚Üí S3 `aq_raw/aq_dev/aq_prod` ‚Üí Glue ‚Üí Athena ‚Üí OWOX ‚Üí Looker Studio).[1][2]

```markdown
# EPIC: OpenAQ v3 Data Pipeline to Athena ‚Üí OWOX ‚Üí Looker Studio

## üéØ Epic Summary
X√¢y d·ª±ng end-to-end data pipeline thu th·∫≠p d·ªØ li·ªáu ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠ t·ª´ **OpenAQ API v3** (Vi·ªát Nam), l∆∞u tr·ªØ tr√™n **S3 (bucket `openaq-data-pipeline`)** v·ªõi 3 zone `aq_raw/`, `aq_dev/`, `aq_prod/`, x·ª≠ l√Ω b·∫±ng **AWS Glue**, query b·∫±ng **Athena**, v√† xu·∫•t sang **OWOX ‚Üí Looker Studio** ƒë·ªÉ t·∫°o dashboard ph√¢n t√≠ch air quality theo th·ªùi gian v√† ƒë·ªãa ƒëi·ªÉm.[web:93][web:98][web:81]

---

## üìå Goals & Non-Goals

### Goals
- T·ª± ƒë·ªông thu th·∫≠p d·ªØ li·ªáu t·ª´ OpenAQ v3 cho c√°c sensor t·∫°i Vi·ªát Nam (2 b∆∞·ªõc: locations ‚Üí measurements).[web:93][web:98]
- L∆∞u **raw JSON.gz immutable** v√†o `aq_raw/` ƒë·ªÉ audit / reprocess.
- X√¢y d·ª±ng **dev** v√† **prod** data zones (`aq_dev/`, `aq_prod/`) v·ªõi d·ªØ li·ªáu Parquet partitioned cho query t·ªëi ∆∞u.[web:31]
- Orchestrate to√†n b·ªô lu·ªìng b·∫±ng **Airflow (Docker local)** qua DAG `openaq_to_athena_pipeline`.[web:14]
- Cung c·∫•p data set chu·∫©n cho **Athena ‚Üí OWOX ‚Üí Looker Studio** (b·∫£ng `vietnam` trong `aq_dev` v√† `aq_prod`).[web:81]

### Non-Goals
- Kh√¥ng x√¢y d·ª±ng UI ri√™ng ngo√†i Looker Studio.
- Kh√¥ng tri·ªÉn khai Airflow managed (MWAA) trong phase ƒë·∫ßu.
- Kh√¥ng s·ª≠ d·ª•ng Redshift; t·∫≠p trung tr√™n S3 + Athena.

---

## üèóÔ∏è High-Level Architecture (Business View)

```
               Airflow (Docker Local)
         ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
         DAG:
           - openaq_to_athena_pipeline

                 ‚îÇ
                 ‚ñº
        AWS Lambda: openaq-fetcher
        - B∆∞·ªõc 1: /v3/locations (VN)
        - B∆∞·ªõc 2: /v3/sensors/{sensor_id}/measurements
        - Ghi raw JSON.gz v√†o S3 (aq_raw/)

                 ‚îÇ
                 ‚ñº
      S3 Bucket: openaq-data-pipeline
      ‚îú‚îÄ‚îÄ aq_raw/    (raw zone: JSON.gz t·ª´ API)
      ‚îú‚îÄ‚îÄ aq_dev/    (dev zone: Parquet, test ETL)
      ‚îî‚îÄ‚îÄ aq_prod/   (prod zone: Parquet, production)

                 ‚îÇ
                 ‚ñº
               AWS Glue
      ‚îú‚îÄ‚îÄ Glue Jobs (dev/prod)
      ‚îÇ   - ƒê·ªçc t·ª´ aq_raw/
      ‚îÇ   - Ghi Parquet v√†o aq_dev/ v√† aq_prod/
      ‚îî‚îÄ‚îÄ Glue Crawlers (raw/dev/prod)
          - C·∫≠p nh·∫≠t Glue Data Catalog

                 ‚îÇ
                 ‚ñº
         Glue Data Catalog
      ‚îú‚îÄ‚îÄ raw_db   (map aq_raw/)
      ‚îú‚îÄ‚îÄ dev_db   (map aq_dev/)
      ‚îî‚îÄ‚îÄ prod_db  (map aq_prod/)

                 ‚îÇ
                 ‚ñº
            Amazon Athena
      ‚îú‚îÄ‚îÄ database: aq_dev
      ‚îÇ   ‚îî‚îÄ‚îÄ table: vietnam
      ‚îî‚îÄ‚îÄ database: aq_prod
          ‚îî‚îÄ‚îÄ table: vietnam

                 ‚îÇ
                 ‚ñº
                 OWOX
      ‚îú‚îÄ‚îÄ source: aq_dev.vietnam
      ‚îî‚îÄ‚îÄ source: aq_prod.vietnam

                 ‚îÇ
                 ‚ñº
            Looker Studio
      ‚îú‚îÄ‚îÄ dataset: aq_dev.vietnam
      ‚îî‚îÄ‚îÄ dataset: aq_prod.vietnam
```

---

## üìÇ Scope & Deliverables

### Data Flow Scope
- **Extract**:
  - Step 1: G·ªçi `GET /v3/locations?iso=VN&...` ƒë·ªÉ l·∫•y danh s√°ch locations + sensors t·∫°i Vi·ªát Nam.[web:98][web:95]
  - Step 2: G·ªçi `GET /v3/sensors/{sensor_id}/measurements?...` ƒë·ªÉ l·∫•y measurements cho t·ª´ng sensor theo ng√†y.[web:93][web:95]
  - L∆∞u raw JSON.gz theo ng√†y v√†o `s3://openaq-data-pipeline/aq_raw/...`.

- **Transform**:
  - Glue Jobs (dev/prod) ƒë·ªçc t·ª´ `raw_db.openaq_raw`.
  - Flatten JSON: location, coordinates, sensor, parameter, value, date.
  - Chu·∫©n h√≥a: `measurement_date`, `country`, `location_name`, `parameter`, `value`.
  - Ghi Parquet partitioned (`measurement_date`, `country`) v√†o `aq_dev/` v√† `aq_prod/`.[web:31]

- **Serve**:
  - Glue Crawlers build `dev_db` v√† `prod_db` cho Athena.[web:84][web:85]
  - Athena databases `aq_dev` v√† `aq_prod` expose table `vietnam` cho OWOX.
  - OWOX chuy·ªÉn ti·∫øp/chu·∫©n h√≥a cho Looker Studio ƒë·ªÉ build dashboard.

### Deliverables
- S3 bucket `openaq-data-pipeline` v·ªõi 3 zone: `aq_raw/`, `aq_dev/`, `aq_prod/` (ƒë√£ c√≥ d·ªØ li·ªáu).[web:15]
- Lambda function `openaq-fetcher` ch·∫°y ƒë∆∞·ª£c end-to-end 2 b∆∞·ªõc API.
- Glue Jobs `openaq-transformer-dev` v√† `openaq-transformer-prod` + Crawlers `dev-crawler`, `prod-crawler`.
- Athena databases `aq_dev`, `aq_prod` v·ªõi table `vietnam`.
- K·∫øt n·ªëi OWOX v√† Looker Studio ho·∫°t ƒë·ªông, hi·ªÉn th·ªã dashboard c∆° b·∫£n (daily PM2.5 by city).

---

## üß© User Stories

### US-1: S3 & IAM Setup
> As a Data Engineer, I want a single S3 bucket with 3 logical zones so that dev/prod data is isolated by prefix, kh√¥ng c·∫ßn qu·∫£n l√Ω nhi·ªÅu bucket.

- Tasks:
  - T·∫°o bucket `openaq-data-pipeline`.
  - T·∫°o prefix `aq_raw/`, `aq_dev/`, `aq_prod/`.
  - T·∫°o IAM roles cho Lambda, Glue, Athena v·ªõi quy·ªÅn truy c·∫≠p prefix ph√π h·ª£p.[web:15]

### US-2: Lambda Ingestion (OpenAQ v3)
> As a Data Engineer, I want Lambda to fetch OpenAQ v3 data (VN) and store raw JSON.gz in S3 so that downstream ETL c√≥ ngu·ªìn d·ªØ li·ªáu immutable, ƒë·∫ßy ƒë·ªß.

- Tasks:
  - Implement step 1: call `/v3/locations?iso=VN`.
  - Implement step 2: call `/v3/sensors/{sensor_id}/measurements` theo ng√†y, ph√¢n trang.
  - Ghi file v√†o `aq_raw/openaq/ingest_date=YYYY-MM-DD/...`.
  - Log s·ªë records, handle errors & retries.

### US-3: Glue ETL - Dev
> As a Data Engineer, I want a dev ETL job that flattens OpenAQ JSON into Parquet in `aq_dev/` so that schema v√† logic c√≥ th·ªÉ test tr∆∞·ªõc khi ƒë∆∞a sang prod.

- Tasks:
  - T·∫°o `raw_db` + `dev_db`.
  - Crawler dev: scand `aq_dev/processed/openaq/`.
  - Job `openaq-transformer-dev`:
    - ƒê·ªçc `raw_db.openaq_raw`.
    - Transform & filter.
    - Ghi `s3://openaq-data-pipeline/aq_dev/` (partitioned).[web:31][web:84]

### US-4: Glue ETL - Prod
> As a Data Engineer, I want a prod ETL job that writes stable Parquet data into `aq_prod/` so that BI v√† b√°o c√°o s·ª≠ d·ª•ng ngu·ªìn ƒë√°ng tin c·∫≠y.

- Tasks:
  - Clone logic t·ª´ dev sang `openaq-transformer-prod`.
  - Output `s3://openaq-data-pipeline/aq_prod/processed/openaq/`.
  - Crawler prod ‚Üí `prod_db` tables.

### US-5: Airflow Orchestration
> As a Platform Engineer, I want Airflow to orchestrate Lambda and Glue so that to√†n b·ªô pipeline ch·∫°y t·ª± ƒë·ªông, c√≥ retry v√† logs t·∫≠p trung.

- Tasks:
  - Ch·∫°y Airflow b·∫±ng Docker local.
  - DAG `openaq_to_athena_pipeline`:
    - `fetch_openaq_raw` ‚Üí `run_glue_etl_dev` ‚Üí `crawl_dev_processed` ‚Üí `run_glue_etl_prod` ‚Üí `crawl_prod_processed`.
  - C·∫•u h√¨nh retry (3 l·∫ßn, 5 ph√∫t delay), alerting c∆° b·∫£n.[web:14]

### US-6: Athena ‚Üí OWOX ‚Üí Looker Studio
> As a Data Analyst, I want to query air quality data from Athena and visualize it in Looker Studio so that c√≥ th·ªÉ theo d√µi PM2.5 theo th·ªùi gian v√† th√†nh ph·ªë.

- Tasks:
  - T·∫°o Athena databases `aq_dev`, `aq_prod` (map t·ª´ Glue dev_db/prod_db).[web:81]
  - T·∫°o b·∫£ng `vietnam`.
  - K·∫øt n·ªëi OWOX t·ªõi Athena/S3 nh∆∞ ngu·ªìn.
  - T·∫°o datasets t∆∞∆°ng ·ª©ng trong Looker Studio.
  - X√¢y 1‚Äì2 dashboard m·∫´u.

---

## ‚úÖ Acceptance Criteria

- Lambda ch·∫°y th√†nh c√¥ng 2 b∆∞·ªõc API, l∆∞u file raw cho √≠t nh·∫•t 1 ng√†y v√†o `aq_raw/`.
- Glue Jobs dev/prod sinh Parquet partitioned v√†o `aq_dev/processed/openaq/` v√† `aq_prod/processed/openaq/`, ƒë∆∞·ª£c Crawlers nh·∫≠n v√† Catalog ho√°.[web:31][web:84]
- Athena query tr√™n `aq_prod.vietnam` tr·∫£ k·∫øt qu·∫£ daily PM2.5 < 5s cho 1 ng√†y d·ªØ li·ªáu.
- OWOX v√† Looker Studio hi·ªÉn th·ªã ƒë∆∞·ª£c dashboard:
  - Top 10 th√†nh ph·ªë c√≥ PM2.5 cao nh·∫•t trong ng√†y.
  - Trend PM2.5 theo th·ªùi gian cho 1 th√†nh ph·ªë.

---